{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JC-IJfoeK7hD",
        "DxrrSG1voiSd",
        "pXWye_RQo3r3",
        "a3rbTo0zMCeW",
        "HYMwvcKasuH4",
        "rRSkfgspLKO2",
        "sV6k8RRkg3h4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **üóÉÔ∏è Data Lab**"
      ],
      "metadata": {
        "id": "JC-IJfoeK7hD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful dataset: [Customer analysis dataset](https://drive.google.com/file/d/1mTKbGB_PJbnilFuf42RFVhkEzACvQkdd/view?usp=drive_link) and [annotations](https://docs.google.com/spreadsheets/d/1CiAxAvS9nYp5NBFv7vG5XBw39a2KBRRx/edit?usp=sharing&ouid=107921194674515097266&rtpof=true&sd=true)\n"
      ],
      "metadata": {
        "id": "48nV7VxI52d0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate samples üéØ"
      ],
      "metadata": {
        "id": "DxrrSG1voiSd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTPPONJHzBR5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_samples = 500 # @param {type:\"integer\"}\n",
        "type_dataset = \"blobs\" # @param [\"noisy_circles\", \"noisy_moons\", \"blobs\", \"no_structure\", \"anisotropic\", \"varied_var\"]\n",
        "noise = 0.04 # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "angle_aniso = 100 # @param {type:\"slider\", min:0, max:180, step:10}\n",
        "random_state = 2 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "\n",
        "if type_dataset == \"noisy_circles\":\n",
        "  X, _ = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"noisy_moons\":\n",
        "  X, _ = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"blobs\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"no_structure\":\n",
        "  X = np.random.rand(n_samples, 2)\n",
        "\n",
        "elif type_dataset == \"anisotropic\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  t = np.tan(np.radians(angle_aniso))\n",
        "  transformation = np.array(((1, t), (0, 1))).T\n",
        "  X = np.dot(X, transformation)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"varied_var\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
        "\n",
        "print (\"\\nData shape: {0} \\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a dataset üìë"
      ],
      "metadata": {
        "id": "pXWye_RQo3r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ---\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown ### üîº Upload your file (first)\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Enter path to **.csv* file:\n",
        "file_path = \"/content/customer_segmentation.csv\" # @param {type:\"string\"}\n",
        "\n",
        "var_h = \"Income\" # @param {type:\"string\"}\n",
        "var_v = \"Age\" # @param {type:\"string\"}\n",
        "labels = \"Sex\" # @param {type:\"string\"}\n",
        "normalization = \"None\" # @param [\"MinMax [0,1]\", \"MinMax [-1,1]\", \"Z-Score\", \"None\"]\n",
        "Load_all_data = True # @param {type:\"boolean\"}\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "if not Load_all_data:\n",
        "  X = np.c_[np.array(data[var_h]), np.array(data[var_v])]\n",
        "else:\n",
        "  X = np.array(data)\n",
        "\n",
        "y = np.array(data[labels]) if labels != \"\" else None\n",
        "\n",
        "if   normalization == \"MinMax [0,1]\":\n",
        "  X = MinMaxScaler().fit_transform(X)\n",
        "elif normalization == \"MinMax [-1,1]\":\n",
        "  X = MinMaxScaler(feature_range=(-1,1)).fit_transform(X)\n",
        "elif normalization == \"Z-Score\":\n",
        "  X = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "if not Load_all_data:\n",
        "  data[var_h], data[var_v] = X[:, 0], X[:, 1]\n",
        "else:\n",
        "  for i in range(len(data.columns)):\n",
        "    data.iloc[:, i] = X[:, i]\n",
        "\n",
        "_, ax = plt.subplots (figsize=(5,4))\n",
        "# ax.scatter(X[:, 0], X[:, 1], c=y, cmap='Paired', edgecolors='k')\n",
        "sns.scatterplot(ax=ax,data=data,x=var_h,y=var_v, hue=labels if labels != \"\" else None, palette='colorblind')\n",
        "print (\"\\nData Loaded! ‚úÖ\")\n",
        "print (\" - Shape: {0}\\n\".format(X.shape))"
      ],
      "metadata": {
        "id": "YP61e7ngtFAE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **üìã Determine the right num of clusters**"
      ],
      "metadata": {
        "id": "a3rbTo0zMCeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import cluster\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics import silhouette_score\n",
        "from IPython.display import clear_output\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "method = \"Silhouette (Both)\" # @param [\"Elbow (KMeans only)\", \"Silhouette (Both)\", \"Dendogram (Agglom only)\"]\n",
        "min_n_clusters = 2 # @param {type:\"integer\"}\n",
        "max_n_clusters = 9 # @param {type:\"integer\"}\n",
        "random_state = 1 # @param {type:\"integer\"}\n",
        "model = \"Kmeans\" # @param [\"Kmeans\", \"MiniBatchKMeans\", \"AgglomerativeClustering\"]\n",
        "random_state = 4 # @param {type:\"integer\"}\n",
        "metric = \"euclidean\" # @param [\"euclidean\", \"cityblock\", \"cosine\", \"l1\", \"l2\", \"chebyshev\", \"mahalanobis\"]\n",
        "linkage = \"ward\" # @param [\"average\", \"complete\", \"single\", \"ward\"]\n",
        "\n",
        "silhouette_distances = []\n",
        "\n",
        "clusters = np.arange(min_n_clusters, max_n_clusters)\n",
        "elbow_distances = []\n",
        "\n",
        "if method == \"Elbow (KMeans only)\":\n",
        "  # Eval kmeans over each num of clusters\n",
        "  for n_cluster in clusters :\n",
        "    #\n",
        "    if model == \"Kmeans\":\n",
        "      algo = cluster.KMeans(n_clusters=n_cluster, random_state=random_state);\n",
        "    elif model == \"MiniBatchKMeans\":\n",
        "      algo = cluster.MiniBatchKMeans(n_clusters=n_cluster, random_state=random_state);\n",
        "    elif model == \"AgglomerativeClustering\":\n",
        "       raise ValueError(\"Model must be either Kmeans or MiniBatchKMeans\")\n",
        "\n",
        "    # algo.fit( X )\n",
        "    predictions = algo.fit_predict( X )\n",
        "    centroids = algo.cluster_centers_\n",
        "    distance = 0\n",
        "\n",
        "    for i in range(len(predictions)) :\n",
        "      centroide = centroids[predictions[i]]\n",
        "      distance += euclidean_distances( centroide.reshape(1, -1) , X[i].reshape(1, -1) )\n",
        "\n",
        "    elbow_distances.extend(distance/len(predictions))\n",
        "\n",
        "  # Plot the elbow\n",
        "  _, ax = plt.subplots (figsize = (7,5))\n",
        "  ax.plot( clusters , elbow_distances , marker=\"x\")\n",
        "  ax.set_title(\"Elbow\")\n",
        "  clear_output()\n",
        "\n",
        "elif method == \"Silhouette (Both)\":\n",
        "  # Eval kmeans over each num of clusters\n",
        "  for n_cluster in clusters :\n",
        "    #\n",
        "    if model == \"Kmeans\":\n",
        "      algo = cluster.KMeans(n_clusters=n_cluster, random_state=random_state);\n",
        "    elif model == \"MiniBatchKMeans\":\n",
        "      algo = cluster.MiniBatchKMeans(n_clusters=n_cluster, random_state=random_state);\n",
        "    elif model == \"AgglomerativeClustering\":\n",
        "      algo = AgglomerativeClustering(n_clusters=n_cluster, linkage=linkage)\n",
        "\n",
        "    # algo.fit( X )\n",
        "    predictions = algo.fit_predict( X )\n",
        "\n",
        "    distance = silhouette_score( X , predictions.reshape(-1,1) , metric=metric)\n",
        "    silhouette_distances.append(distance)\n",
        "\n",
        "  # Plot the silhouette\n",
        "  _, ax = plt.subplots (figsize = (7,5))\n",
        "  ax.plot( clusters , silhouette_distances , marker=\"x\")\n",
        "  ax.set_title(\"Silhouette\")\n",
        "  clear_output()\n",
        "\n",
        "elif method == \"Dendogram (Agglom only)\":\n",
        "  #\n",
        "  if model == \"Kmeans\" or model == \"MiniBatchKMeans\" :\n",
        "       raise ValueError(\"AgglomerativeClustering\")\n",
        "  plt.figure(figsize =(7,5))\n",
        "  plt.title('Dendrogram')\n",
        "  Dendrogram = shc.dendrogram((shc.linkage(X, method='ward')))\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print (\"\\nDone! ‚úÖ \\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-5m67-XQTbnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **ü§ñ Setup Model**"
      ],
      "metadata": {
        "id": "HYMwvcKasuH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "model_type = \"Kmeans\" # @param [\"Kmeans\", \"MiniBatchKMeans\", \"AgglomerativeClustering\"]\n",
        "n_clusters = 2 # @param {type:\"integer\"}\n",
        "max_steps = 300 # @param {type:\"integer\"}\n",
        "linkage = \"ward\" # @param [\"average\", \"complete\", \"single\", \"ward\"]\n",
        "# distance_threshold = 1.2 # @param\n",
        "\n",
        "if model_type == \"AgglomerativeClustering\":\n",
        "  algo = cluster.AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
        "elif model_type == \"Kmeans\":\n",
        "  algo = cluster.KMeans(n_clusters=n_clusters, random_state=random_state);\n",
        "elif model_type == \"MiniBatchKMeans\":\n",
        "  algo = cluster.MiniBatchKMeans(n_clusters=n_clusters, random_state=random_state);\n",
        "\n",
        "\n",
        "print (\"\\nModel is ready!‚öôÔ∏èüîß\\n\")\n",
        "# print (\"----- \")\n",
        "print (\" - Model: {0}\".format(model_type))\n",
        "print (\" - n_clusters: {0}\".format(n_clusters))\n",
        "print (\" - max_steps: {0}\".format(max_steps))\n",
        "if model_type == \"AgglomerativeClustering\": print (\" - linkage: {0}\".format(linkage))"
      ],
      "metadata": {
        "id": "GdOQ8eLPMEID",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ü¶æ Run training!**"
      ],
      "metadata": {
        "id": "rRSkfgspLKO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @markdown ### Start now!\n",
        "# @markdown \\\n",
        "\n",
        "algo.fit(X)\n",
        "\n",
        "# silhouette_average_score = silhouette_score(X, agglom.fit_predict(X))\n",
        "# silhouette_scores.append(silhouette_average_score)\n",
        "\n",
        "print (\"\\nTraining done! ‚úÖ\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "51EH-FHOxqPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üí° Analyze and Look for Insights!**"
      ],
      "metadata": {
        "id": "sV6k8RRkg3h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @markdown ### üìä Display result\n",
        "# @markdown \\\n",
        "\n",
        "plot_type = \"Boxplot\" # @param [\"Scatter\", \"Boxplot\"]\n",
        "# distance_threshold = 1.2 # @param\n",
        "h_axis_name = \"Occupation\" # @param {type:\"string\"}\n",
        "v_axis_name = \"Age\" # @param {type:\"string\"}\n",
        "\n",
        "# plt.scatter(X[:, 0], X[:, 1], c=agglom.fit_predict(X))\n",
        "\n",
        "if \"cluster\" not in data.columns:\n",
        "  data.insert((data.shape[1]),'cluster',algo.fit_predict(X))\n",
        "else:\n",
        "  data['cluster'] = algo.fit_predict(X)\n",
        "\n",
        "\n",
        "\n",
        "# labels if labels != \"\" else None,\n",
        "_, ax = plt.subplots (figsize=(5,4))\n",
        "\n",
        "if plot_type == \"Scatter\":\n",
        "  sns.scatterplot(ax=ax,data=data,x=h_axis_name,y=v_axis_name, hue=\"cluster\", palette='colorblind')\n",
        "elif plot_type == \"Boxplot\":\n",
        "  sns.boxplot(ax=ax,data=data,x=h_axis_name,y=v_axis_name, hue=\"cluster\", palette='colorblind')\n",
        "\n",
        "\n",
        "plt.title(\"{0} clusters\".format(n_clusters))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Yk546AEdMHA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @markdown ### üìä Plot all variables\n",
        "# @markdown \\\n",
        "\n",
        "cluster_id = 1 # @param {type:\"integer\"}\n",
        "\n",
        "data[data['cluster'] == cluster_id].hist(figsize = (12,10), grid=False, alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F6XTvFfrYRhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}