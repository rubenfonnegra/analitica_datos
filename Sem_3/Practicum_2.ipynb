{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r8VgexHSA_Qd",
        "DxrrSG1voiSd",
        "pXWye_RQo3r3",
        "rRSkfgspLKO2",
        "B5H9RZazPquo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **üóÉÔ∏è Data Lab**"
      ],
      "metadata": {
        "id": "r8VgexHSA_Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate samples üéØ"
      ],
      "metadata": {
        "id": "DxrrSG1voiSd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uTPPONJHzBR5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_samples = 300 # @param {type:\"integer\"}\n",
        "type_dataset = \"blobs\" # @param [\"noisy_circles\", \"noisy_moons\", \"blobs\", \"no_structure\", \"anisotropic\", \"varied_var\"]\n",
        "noise = 0.1 # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "angle_aniso = 110 # @param {type:\"slider\", min:0, max:180, step:10}\n",
        "random_state = 1 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "\n",
        "if type_dataset == \"noisy_circles\":\n",
        "  X, _ = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"noisy_moons\":\n",
        "  X, _ = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"blobs\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, cluster_std=noise*5, random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"no_structure\":\n",
        "  X = np.random.rand(n_samples, 2)\n",
        "\n",
        "elif type_dataset == \"anisotropic\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  t = np.tan(np.radians(angle_aniso))\n",
        "  transformation = np.array(((1, t), (0, 1))).T\n",
        "  X = np.dot(X, transformation)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"varied_var\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
        "\n",
        "print (\"\\nData shape: {0} \\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a dataset üìë"
      ],
      "metadata": {
        "id": "pXWye_RQo3r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ---\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown ### üîº Upload your file (first)\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Enter path to **.csv* file:\n",
        "file_path = \"/content/heart_disease_uci.csv\" # @param {type:\"string\"}\n",
        "\n",
        "var_h = \"age\" # @param {type:\"string\"}\n",
        "var_v = \"chol\" # @param {type:\"string\"}\n",
        "labels = \"\" # @param {type:\"string\"}\n",
        "normalization = \"None\" # @param [\"MinMax [0,1]\", \"MinMax [-1,1]\", \"Z-Score\", \"None\"]\n",
        "Load_all_data = True # @param {type:\"boolean\"}\n",
        "Remove_missing = True # @param {type:\"boolean\"}\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "if Remove_missing:\n",
        "  data = data.dropna()\n",
        "\n",
        "if not Load_all_data:\n",
        "  X = np.c_[np.array(data[var_h]), np.array(data[var_v])]\n",
        "else:\n",
        "  X = np.array(data)\n",
        "\n",
        "y = np.array(data[labels]) if labels != \"\" else None\n",
        "\n",
        "if   normalization == \"MinMax [0,1]\":\n",
        "  X = MinMaxScaler().fit_transform(X)\n",
        "elif normalization == \"MinMax [-1,1]\":\n",
        "  X = MinMaxScaler(feature_range=(-1,1)).fit_transform(X)\n",
        "elif normalization == \"Z-Score\":\n",
        "  X = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "if not Load_all_data:\n",
        "  data[var_h], data[var_v] = X[:, 0], X[:, 1]\n",
        "else:\n",
        "  for i in range(len(data.columns)):\n",
        "    data.iloc[:, i] = X[:, i]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "_, ax = plt.subplots (figsize=(5,4))\n",
        "# ax.scatter(X[:, 0], X[:, 1], c=y, cmap='Paired', edgecolors='k')\n",
        "sns.scatterplot(ax=ax,data=data,x=var_h,y=var_v, hue=labels if labels != \"\" else None, palette='colorblind')\n",
        "print (\"\\nData Loaded! ‚úÖ\")\n",
        "print (\" - Shape: {0}\\n\".format(X.shape))"
      ],
      "metadata": {
        "id": "YP61e7ngtFAE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ü§ñ Run training!**"
      ],
      "metadata": {
        "id": "rRSkfgspLKO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from natsort import natsorted, ns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from sklearn.datasets import make_blobs\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# @markdown ### üìã Set up K-Means\n",
        "# @markdown \\\n",
        "\n",
        "class Interactive_KMeans():\n",
        "    def __init__ (self, n_clusters=5, nsteps=10, random_state=2):\n",
        "      #\n",
        "      self.n_clusters = n_clusters\n",
        "      self.nsteps = nsteps\n",
        "      self.random_state = np.random.RandomState(random_state)\n",
        "\n",
        "    def plot_points(self, X, labels, n_clusters):\n",
        "        plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis',\n",
        "                    vmin=0, vmax=n_clusters - 1);\n",
        "\n",
        "    def plot_centers(self, centers, edgecolors='r'):\n",
        "        plt.scatter(centers[:, 0], centers[:, 1], marker='o', facecolors=\"none\",\n",
        "                    s=200, edgecolors=edgecolors, linewidth=3)\n",
        "        # plt.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "        #             c='black', s=50)\n",
        "\n",
        "    def save_gif (self, path, output_file='out.gif'):\n",
        "        list_files = natsorted(os.listdir(path), alg=ns.PATH)\n",
        "        all_images = []\n",
        "\n",
        "        # Save a gif\n",
        "        for file_ in list_files[1:]:\n",
        "          img = Image.open(path + file_)\n",
        "          all_images.append(img)\n",
        "\n",
        "        img = Image.open(path + list_files[0])\n",
        "        img.save(output_file, save_all=True, append_images=all_images, duration=500, loop=0)\n",
        "        os.system('rm -r {0}'.format(path))\n",
        "\n",
        "\n",
        "    def fit(self, X, output_file='kmeans.gif', tol=1e-4, noise=0.1):\n",
        "        os.makedirs('/images/', exist_ok = True)\n",
        "        labels = np.zeros(X.shape[0])\n",
        "        centers_ = self.random_state.randn(self.n_clusters, 2)\n",
        "        converged_frame = 0\n",
        "\n",
        "        print (\"Plots... \\n\")\n",
        "\n",
        "        for i in range(self.nsteps + 1):\n",
        "            old_centers = centers_.copy()\n",
        "            labels = pairwise_distances_argmin(X, centers_)\n",
        "\n",
        "            centers_ = np.array([X[labels == j].mean(0) for j in range(self.n_clusters)])\n",
        "            nans = np.isnan(centers_)\n",
        "            centers_[nans] = old_centers[nans]+self.random_state.randn()*noise\n",
        "\n",
        "            #Validate centers are separated enough\n",
        "            for m in range(len(centers_)):\n",
        "              for n in range(m+1, len(centers_)):\n",
        "                if abs(centers_[m, :]-centers_[n, :]).mean()<abs(X.min()-X.max())*0.01:\n",
        "                   centers_[n, :] += self.random_state.randn()*noise*0.5\n",
        "                   centers_[m, :] += self.random_state.randn()*noise*0.5\n",
        "\n",
        "            # #Validate centers are separated enough\n",
        "            if abs(centers_ - old_centers).all() < tol:\n",
        "              converged_frame += 1\n",
        "              if converged_frame > 5: break\n",
        "\n",
        "            # plot the data and cluster centers\n",
        "            self.plot_points(X, labels, self.n_clusters)\n",
        "            self.plot_centers(old_centers, edgecolors='b')\n",
        "\n",
        "            for n in range(self.n_clusters):\n",
        "                plt.annotate('', centers_[n], old_centers[n],\n",
        "                            arrowprops=dict(arrowstyle='->', color='r', linewidth=3))\n",
        "\n",
        "            self.plot_centers(centers_, edgecolors='r')\n",
        "\n",
        "            plt.savefig('/images/{0}.png'.format(i), bbox_inches=0, pad_inches='tight')\n",
        "            plt.close(), plt.clf()\n",
        "\n",
        "        self.save_gif ('/images/', output_file=output_file)\n",
        "        self.centers_ = centers_\n",
        "\n",
        "\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_clusters = 3 # @param {type:\"integer\"}\n",
        "max_steps = 10 # @param {type:\"integer\"}\n",
        "random_state = 2 # @param {type:\"integer\"}\n",
        "\n",
        "kmeans = Interactive_KMeans(n_clusters=n_clusters, nsteps=max_steps, random_state=random_state);\n",
        "\n",
        "print (\"\\nModel is ready!\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GdOQ8eLPMEID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @markdown ### Start now ü¶æ\n",
        "# @markdown \\\n",
        "\n",
        "kmeans.fit(X, output_file='kmeans_{0}.gif'.format(random_state))\n",
        "\n",
        "print (\"\\nTraining done! ‚úÖ\")\n"
      ],
      "metadata": {
        "id": "51EH-FHOxqPZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @markdown ### üìä Display result\n",
        "# @markdown \\\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "\n",
        "with open('kmeans_{0}.gif'.format(random_state),'rb') as f:\n",
        "    display.Image(data=f.read(), format='png')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Yk546AEdMHA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üå≥ Code Lab - Coming back to roots**"
      ],
      "metadata": {
        "id": "B5H9RZazPquo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "h5u8qNw0kiDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doDxF-71moJX"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters = _ , random_state = )\n",
        "\n",
        "# Train Kmeans\n",
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3omuk5G0pB30"
      },
      "outputs": [],
      "source": [
        "# Plot centroids\n",
        "centroids = _\n",
        "labels = _\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U1eSNp5moJh"
      },
      "outputs": [],
      "source": [
        "# Create predictions\n",
        "predictions = kmeans.predict( _ )\n",
        "print (predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYfrH3XIUZ0K"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots (1,2, figsize=(8,4))\n",
        "\n",
        "# plot data and found centroids\n",
        "axes[1].scatter( _ , _ , c = _ , edgecolors='k', cmap='Paired')"
      ]
    }
  ]
}