{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC-IJfoeK7hD"
      },
      "source": [
        "# **üóÉÔ∏è Data Lab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48nV7VxI52d0"
      },
      "source": [
        "Useful datasets:\n",
        "- [Fruits dataset](https://drive.google.com/file/d/1Jn15Qra1NldKC6ELVTTFWrqZ5OJdK5pL/view?usp=sharing)\n",
        "- [Car maintainance](https://drive.google.com/file/d/1t4mKvvw6VR6Bx4OwZ8SeMRd18kd7hvz9/view?usp=sharing)\n",
        "- [Energy consumption](https://drive.google.com/file/d/1iMkGEG4TBUw0FreaT4Gf2gnm3MEjFG1x/view?usp=sharing)\n",
        "- [Students Performance](https://drive.google.com/file/d/1YwqZvaf0B7gW0cutfgD7berjkBSRVzPk/view?usp=sharing)\n",
        "- [Heart Disease](https://drive.google.com/file/d/1lQ-3-dmVpJBq0eXcQp3nRgKNnn-TAP_n/view?usp=sharing)\n",
        "- [Medical insurance](https://drive.google.com/file/d/1n_An4atBisD6FlO8k467Iz2sZjsujVF5/view?usp=sharing)\n",
        "- [Phone price dataset](https://drive.google.com/file/d/1zh7byFuQo8Wg-Wzpu9TGo2VzhqCR6y7K/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxrrSG1voiSd"
      },
      "source": [
        "## Generate samples üéØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uTPPONJHzBR5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_samples = 300 # @param {type:\"integer\"}\n",
        "type_dataset = \"linear_reg\" # @param [\"noisy_circles\", \"noisy_moons\", \"blobs\", \"no_structure\", \"anisotropic\", \"varied_var\", \"linear_reg\", \"nonlinear_reg\"]\n",
        "noise = 0.19 # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "angle_aniso = 110 # @param {type:\"slider\", min:0, max:180, step:10}\n",
        "deg_reg = 3 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "random_state = 1 # @param {type:\"integer\"}\n",
        "return_classes = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "\n",
        "if type_dataset == \"noisy_circles\":\n",
        "  X, y = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"noisy_moons\":\n",
        "  X, y = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"blobs\":\n",
        "  X, y = datasets.make_blobs(n_samples=n_samples, cluster_std=noise*5, random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"no_structure\":\n",
        "  X = np.random.rand(n_samples, 2)\n",
        "\n",
        "elif type_dataset == \"anisotropic\":\n",
        "  X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  t = np.tan(np.radians(angle_aniso))\n",
        "  transformation = np.array(((1, t), (0, 1))).T\n",
        "  X = np.dot(X, transformation)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"varied_var\":\n",
        "  X, y = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"linear_reg\":\n",
        "  X, y = datasets.make_regression(n_samples = n_samples , n_features = 1, noise = noise * 100, random_state = random_state)\n",
        "  X = np.c_[X, y]\n",
        "\n",
        "elif type_dataset == \"nonlinear_reg\":\n",
        "  X, y = datasets.make_regression(n_samples = n_samples , n_features = 1, noise = noise * 100, random_state = random_state)\n",
        "  y = (y * 0.1) ** deg_reg\n",
        "  X = np.c_[X, y]\n",
        "\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "if return_classes:\n",
        "  ax.scatter(X[:, 0], X[:, 1], c = y, edgecolors='k', cmap='Paired')\n",
        "else:\n",
        "  ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
        "\n",
        "print (\"\\nData shape: {0} \\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXWye_RQo3r3"
      },
      "source": [
        "## Load a dataset üìë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YP61e7ngtFAE"
      },
      "outputs": [],
      "source": [
        "# @markdown ---\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown ### üîº Upload your file (first)\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Enter path to **.csv* file:\n",
        "file_path = \"\" # @param {type:\"string\"}\n",
        "delimiter = \",\" # @param {type:\"string\"}\n",
        "\n",
        "var_h = \"\" # @param {type:\"string\"}\n",
        "var_v = \"\" # @param {type:\"string\"}\n",
        "labels = \"\" # @param {type:\"string\"}\n",
        "normalization = \"None\" # @param [\"MinMax [0,1]\", \"MinMax [-1,1]\", \"Z-Score\", \"None\"]\n",
        "Load_all_data = False # @param {type:\"boolean\"}\n",
        "Remove_missing = True # @param {type:\"boolean\"}\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "if Remove_missing:\n",
        "  data = data.dropna()\n",
        "\n",
        "if not Load_all_data:\n",
        "  X = np.c_[np.array(data[var_h]), np.array(data[var_v])]\n",
        "else:\n",
        "  X = np.array(data)\n",
        "\n",
        "y = np.array(data[labels]) if labels != \"\" else None\n",
        "\n",
        "if   normalization == \"MinMax [0,1]\":\n",
        "  X = MinMaxScaler(feature_range=( 0,1)).fit_transform(X)\n",
        "elif normalization == \"MinMax [-1,1]\":\n",
        "  X = MinMaxScaler(feature_range=(-1,1)).fit_transform(X)\n",
        "elif normalization == \"Z-Score\":\n",
        "  X = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "if not Load_all_data:\n",
        "  data[var_h], data[var_v] = X[:, 0], X[:, 1]\n",
        "else:\n",
        "  for i in range(len(data.columns)):\n",
        "    data.iloc[:, i] = X[:, i]\n",
        "\n",
        "\n",
        "_, ax = plt.subplots (figsize=(5,4))\n",
        "# ax.scatter(X[:, 0], X[:, 1], c=y, cmap='Paired', edgecolors='k')\n",
        "sns.scatterplot(ax=ax,data=data,x=var_h,y=var_v, hue=labels if labels != \"\" else None, palette='colorblind')\n",
        "print (\"\\nData Loaded! ‚úÖ\")\n",
        "print (\" - Shape: {0}\\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJbFYZLULD_u"
      },
      "source": [
        "# **üìã Model Lab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKCdkAQWx7Vm"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pe_aDliK0FKf"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm, linear_model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "is_regression = False\n",
        "model = \"SVM\" # @param [\"LinearRegression\", \"LogisticRegression\", \"SVM\", \"kNN\", \"Bayes\", \"Decision Tree\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown \\\n",
        "# @markdown ### ‚úèÔ∏è Additional Params\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è SVM\n",
        "# @markdown \\\n",
        "\n",
        "C = 1 # @param {type:\"number\"}\n",
        "gamma = 5 # @param {type:\"number\"}\n",
        "degree = 3 # @param {type:\"integer\"}\n",
        "kernel = \"rbf\" # @param [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è kNN\n",
        "# @markdown \\\n",
        "\n",
        "num_neighbors = 3 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è Naive Gaussian\n",
        "# @markdown \\\n",
        "\n",
        "dist = \"Gaussian\" # @param [\"Gaussian\", \"Bernoulli\", \"Multinomial\"]\n",
        "\n",
        "####### ----------------------------\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "if model == \"LinearRegression\":\n",
        "  algo = linear_model.LinearRegression()\n",
        "\n",
        "if model == \"LogisticRegression\":\n",
        "  algo = linear_model.LogisticRegression()\n",
        "\n",
        "elif model == \"SVM\":\n",
        "  algo = svm.SVC(kernel=kernel, degree=degree, gamma=gamma, C=C)\n",
        "\n",
        "elif model == \"kNN\":\n",
        "  algo = KNeighborsClassifier(n_neighbors=num_neighbors)\n",
        "\n",
        "elif model == \"Bayes\":\n",
        "  if dist == \"Gaussian\":\n",
        "    algo = naive_bayes.GaussianNB()\n",
        "  elif dist == \"Bernoulli\":\n",
        "    algo = naive_bayes.BernoulliNB()\n",
        "  elif dist == \"Multinomial\":\n",
        "    algo = naive_bayes.MultinomialNB()\n",
        "\n",
        "elif model == \"Decision Tree\":\n",
        "  algo = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "\n",
        "print (\"\\nModel is ready!‚öôÔ∏èüîß\\n\")\n",
        "# print (\"----- \")\n",
        "print (\" - Model: {0}\".format(model))\n",
        "\n",
        "if model == \"SVM\":\n",
        "  print (\" - kernel: {0}\".format(kernel))\n",
        "  if kernel == 'poly':\n",
        "    print (\" - degree: {0}\".format(degree))\n",
        "  print (\" - gamma: {0}\".format(gamma))\n",
        "  print (\" - C: {0}\".format(C))\n",
        "\n",
        "if model == \"kNN\":\n",
        "  print (\" - Num neighbors: {0}\".format(num_neighbors))\n",
        "\n",
        "if model == \"Bayes\":\n",
        "  print (\" - Distribution: {0}\".format(dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfIAey2YMQge"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ld4cCXV5MUxa"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm, linear_model\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "is_regression = True\n",
        "model = \"LinearRegression\" # @param [\"LinearRegression\", \"SVR\", \"kNR\", \"Bayesian Ridge\", \"Kernel Ridge\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown \\\n",
        "# @markdown ### ‚úèÔ∏è Aditional Params\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è SVR\n",
        "# @markdown \\\n",
        "\n",
        "C = 1 # @param {type:\"number\"}\n",
        "gamma = 1 # @param {type:\"number\"}\n",
        "degree = 3 # @param {type:\"integer\"}\n",
        "kernel = \"rbf\" # @param [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è kNR\n",
        "# @markdown \\\n",
        "\n",
        "num_neighbors = 3 # @param {type:\"integer\"}\n",
        "weights = \"uniform\" # @param [\"uniform\", \"distance\"]\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è Kernel Ridge\n",
        "# @markdown \\\n",
        "\n",
        "C = 1 # @param {type:\"number\"}\n",
        "gamma = 1 # @param {type:\"number\"}\n",
        "degree = 3 # @param {type:\"integer\"}\n",
        "kernel = \"rbf\" # @param [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
        "\n",
        "####### ----------------------------\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "if model == \"LinearRegression\":\n",
        "  algo = linear_model.LinearRegression()\n",
        "\n",
        "elif model == \"SVR\":\n",
        "  algo = svm.SVR(kernel=kernel, degree=degree, gamma=gamma, C=C)\n",
        "\n",
        "elif model == \"kNR\":\n",
        "  algo = KNeighborsRegressor(n_neighbors=num_neighbors, weights=weights)\n",
        "\n",
        "elif model == \"Bayesian Ridge\":\n",
        "  algo = linear_model.BayesianRidge()\n",
        "\n",
        "elif model == \"Kernel Ridge\":\n",
        "  algo = KernelRidge(kernel=kernel, degree=degree, gamma=gamma)\n",
        "\n",
        "\n",
        "\n",
        "print (\"\\nModel is ready!‚öôÔ∏èüîß\\n\")\n",
        "# print (\"----- \")\n",
        "print (\" - Model: {0}\".format(model))\n",
        "\n",
        "if model == \"SVR\":\n",
        "  print (\" - kernel: {0}\".format(kernel))\n",
        "  if kernel == 'poly':\n",
        "    print (\" - degree: {0}\".format(degree))\n",
        "  print (\" - gamma: {0}\".format(gamma))\n",
        "  print (\" - C: {0}\".format(C))\n",
        "\n",
        "if model == \"kNR\":\n",
        "  print (\" - Num neighbors: {0}\".format(num_neighbors))\n",
        "  print (\" - Weights: {0}\".format(num_neighbors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRSkfgspLKO2"
      },
      "source": [
        "# **ü§ñ Run training!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yZZKIePgDV7B"
      },
      "outputs": [],
      "source": [
        "from itertools import cycle, islice\n",
        "\n",
        "# @markdown ### Start now ü¶æ\n",
        "# @markdown \\\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "ax.set_title(\"{0}\".format(model))\n",
        "\n",
        "print (\"\\nTraining done! ‚úÖ\")\n",
        "\n",
        "if not is_regression:\n",
        "  algo.fit(X, y)\n",
        "  pred = algo.predict(X)\n",
        "  colors = np.array(list(islice(cycle([\"#377eb8\", \"#ff7f00\", \"#4daf4a\", \"#f781bf\", \"#a65628\", \\\n",
        "                                     \"#984ea3\", \"#999999\", \"#e41a1c\", \"#dede00\", \"#000000\"]), int(max(pred) + 1),)))\n",
        "\n",
        "  ax.scatter(X[:, 0], X[:, 1], c=colors[pred], edgecolors='k')\n",
        "  print (\"Plots... \\n\")\n",
        "else:\n",
        "  algo.fit(X[:, :-1], X[:, -1:])\n",
        "  pred = algo.predict(X[:, :-1])\n",
        "  X_, pred_ = zip(*sorted(zip(X[:, 0], pred)))\n",
        "  ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
        "  ax.plot(X_, pred_, c='r')\n",
        "  print (\"Plots... \\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E4063nWw1uTl"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# @markdown ### üìä Compute metrics\n",
        "# @markdown \\\n",
        "# @markdown #### Classification\n",
        "\n",
        "compute_confusion_matrix = False # @param {type:\"boolean\"}\n",
        "compute_metrics_report = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown #### Regression\n",
        "compute_mae_mse = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if compute_confusion_matrix:\n",
        "    #\n",
        "    predictions = algo.predict(X)\n",
        "    cm_ = confusion_matrix(y, predictions, normalize='true')\n",
        "\n",
        "    _, ax = plt.subplots (figsize=(5,3))\n",
        "    sns.heatmap(cm_, annot=True, cmap='hot', ax= ax)\n",
        "\n",
        "if compute_metrics_report:\n",
        "    #\n",
        "    print(classification_report(y, predictions))\n",
        "\n",
        "if compute_mae_mse:\n",
        "    #\n",
        "    predictions = algo.predict(X[:, :-1])\n",
        "    mae_ = mean_absolute_error(X[:, :-1], predictions)\n",
        "    mse_ = mean_squared_error (X[:, :-1], predictions)\n",
        "    print(\"MAE: {0:0.5f}\".format(mae_))\n",
        "    print(\"MSE: {0:0.5f}\".format(mse_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üå≥ Code Lab - Coming back to roots**"
      ],
      "metadata": {
        "id": "B5H9RZazPquo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier as kNN"
      ],
      "metadata": {
        "id": "h5u8qNw0kiDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doDxF-71moJX"
      },
      "outputs": [],
      "source": [
        "knn = kNN(num_neighbors = _ )\n",
        "\n",
        "# Train kNN\n",
        "_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U1eSNp5moJh"
      },
      "outputs": [],
      "source": [
        "# Create predictions\n",
        "predictions = knn.predict( _ )\n",
        "print (predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYfrH3XIUZ0K"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots (1,2, figsize=(8,4))\n",
        "\n",
        "# plot data and labels\n",
        "axes[1].scatter( _ , _ , c = _ , edgecolors='k', cmap='Paired')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JC-IJfoeK7hD",
        "DxrrSG1voiSd",
        "pXWye_RQo3r3",
        "eJbFYZLULD_u",
        "TKCdkAQWx7Vm",
        "rfIAey2YMQge",
        "rRSkfgspLKO2",
        "B5H9RZazPquo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}