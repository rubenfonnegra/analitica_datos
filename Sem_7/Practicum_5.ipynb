{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC-IJfoeK7hD"
      },
      "source": [
        "# **üóÉÔ∏è Data Lab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48nV7VxI52d0"
      },
      "source": [
        "Useful dataset: [Mall customer dataset](https://drive.google.com/file/d/1jACghC-it0Hlb091tc2BH_RgrFWOXXih/view?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxrrSG1voiSd"
      },
      "source": [
        "## Generate samples üéØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uTPPONJHzBR5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_samples = 500 # @param {type:\"integer\"}\n",
        "type_dataset = \"blobs\" # @param [\"noisy_circles\", \"noisy_moons\", \"blobs\", \"no_structure\", \"anisotropic\", \"varied_var\"]\n",
        "noise = 0.04 # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "angle_aniso = 100 # @param {type:\"slider\", min:0, max:180, step:10}\n",
        "random_state = 2 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "\n",
        "if type_dataset == \"noisy_circles\":\n",
        "  X, _ = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"noisy_moons\":\n",
        "  X, _ = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"blobs\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"no_structure\":\n",
        "  X = np.random.rand(n_samples, 2)\n",
        "\n",
        "elif type_dataset == \"anisotropic\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  t = np.tan(np.radians(angle_aniso))\n",
        "  transformation = np.array(((1, t), (0, 1))).T\n",
        "  X = np.dot(X, transformation)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"varied_var\":\n",
        "  X, _ = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
        "\n",
        "print (\"\\nData shape: {0} \\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXWye_RQo3r3"
      },
      "source": [
        "## Load a dataset üìë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP61e7ngtFAE"
      },
      "outputs": [],
      "source": [
        "# @markdown ---\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown ### üîº Upload your file (first)\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Enter path to **.csv* file:\n",
        "file_path = \"/content/Mall_Customers.csv\" # @param {type:\"string\"}\n",
        "\n",
        "var_h = \"Spending Score (1-100)\" # @param {type:\"string\"}\n",
        "var_v = \"Annual Income (k$)\" # @param {type:\"string\"}\n",
        "labels = \"Gender\" # @param {type:\"string\"}\n",
        "normalization = \"MinMax [0,1]\" # @param [\"MinMax [0,1]\", \"MinMax [-1,1]\", \"Z-Score\", \"None\"]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv(file_path)\n",
        "X = np.c_[np.array(data[var_h]), np.array(data[var_v])]\n",
        "y = np.array(data[labels]) if labels != \"\" else None\n",
        "\n",
        "if   normalization == \"MinMax [0,1]\":\n",
        "  X = MinMaxScaler().fit_transform(X)\n",
        "elif normalization == \"MinMax [-1,1]\":\n",
        "  X = MinMaxScaler(feature_range=(-1,1)).fit_transform(X)\n",
        "elif normalization == \"Z-Score\":\n",
        "  X = StandardScaler().fit_transform(X)\n",
        "\n",
        "data[var_h], data[var_v] = X[:, 0], X[:, 1]\n",
        "\n",
        "_, ax = plt.subplots (figsize=(5,4))\n",
        "# ax.scatter(X[:, 0], X[:, 1], c=y, cmap='Paired', edgecolors='k')\n",
        "sns.scatterplot(ax=ax,data=data,x=var_h,y=var_v, hue=labels if labels != \"\" else None, palette='colorblind')\n",
        "print (\"\\nData Loaded! ‚úÖ \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3rbTo0zMCeW"
      },
      "source": [
        " # **üìã Set up Agglomerative Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ASeL6Njl7TeG"
      },
      "outputs": [],
      "source": [
        "# @markdown ---\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ## Compute dendogram\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "plt.figure(figsize =(8, 6))\n",
        "plt.title('Dendrogram')\n",
        "Dendrogram = shc.dendrogram((shc.linkage(X, method='ward')))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GdOQ8eLPMEID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_clusters = 2 # @param {type:\"integer\"}\n",
        "max_steps = 1 # @param {type:\"integer\"}\n",
        "linkage = \"ward\" # @param [\"average\", \"complete\", \"single\", \"ward\"]\n",
        "# distance_threshold = 1.2 # @param\n",
        "\n",
        "agglom = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
        "\n",
        "silhouette_scores = []\n",
        "print (\"\\nModel is ready!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRSkfgspLKO2"
      },
      "source": [
        "# **ü§ñ Run training!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "51EH-FHOxqPZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @markdown ### Start now ü¶æ\n",
        "# @markdown \\\n",
        "\n",
        "agglom.fit(X)\n",
        "\n",
        "silhouette_average_score = silhouette_score(X, agglom.fit_predict(X))\n",
        "silhouette_scores.append(silhouette_average_score)\n",
        "\n",
        "print (\"\\nTraining done! ‚úÖ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yk546AEdMHA6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# @markdown ### üìä Display result\n",
        "# @markdown \\\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=agglom.fit_predict(X))\n",
        "plt.title(\"{0} clusters\".format(n_clusters))\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JC-IJfoeK7hD",
        "DxrrSG1voiSd",
        "pXWye_RQo3r3",
        "a3rbTo0zMCeW",
        "rRSkfgspLKO2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
